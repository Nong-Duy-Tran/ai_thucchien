{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ff9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"sk-0Tq-h91HomLFKER48zIiXA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c513472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ch√†o b·∫°n. V·ªõi t∆∞ c√°ch l√† m·ªôt chuy√™n gia AI t·∫°i Vi·ªát Nam, t√¥i r·∫•t vui ƒë∆∞·ª£c cung c·∫•p cho b·∫°n m·ªôt b·ª©c tranh to√†n c·∫£nh v√† chi ti·∫øt v·ªÅ lƒ©nh v·ª±c tr√≠ tu·ªá nh√¢n t·∫°o (AI) trong n∆∞·ªõc, c·∫≠p nh·∫≠t ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, nƒÉm 2025.\n",
      "\n",
      "NƒÉm 2025 l√† m·ªôt nƒÉm b·∫£n l·ªÅ, ƒë√°nh d·∫•u s·ª± tr∆∞·ªüng th√†nh v∆∞·ª£t b·∫≠c c·ªßa h·ªá sinh th√°i AI Vi·ªát Nam. Ch√∫ng ta ƒë√£ chuy·ªÉn t·ª´ giai ƒëo·∫°n \"th·ª≠ nghi·ªám v√† h·ªçc h·ªèi\" sang giai ƒëo·∫°n \"tri·ªÉn khai s√¢u r·ªông v√† t·∫°o ra gi√° tr·ªã th·ª±c ti·ªÖn\".\n",
      "\n",
      "D∆∞·ªõi ƒë√¢y l√† nh·ªØng th√¥ng tin t·ªïng h·ª£p n·ªïi b·∫≠t nh·∫•t:\n",
      "\n",
      "### **1. Xu H∆∞·ªõng Ch·ªß ƒê·∫°o: AI T·∫°o Sinh v√† AI Theo Ng√†nh D·ªçc**\n",
      "\n",
      "*   **B√πng n·ªï c√°c M√¥ h√¨nh Ng√¥n ng·ªØ L·ªõn (LLM) thu·∫ßn Vi·ªát:**\n",
      "    *   **Ph·ªüGPT 3.0 (c·ªßa VinAI):** ƒê√£ tr·ªü th√†nh m√¥ h√¨nh ng√¥n ng·ªØ ti·∫øng Vi·ªát m·∫°nh m·∫Ω nh·∫•t, ƒë∆∞·ª£c tinh ch·ªânh s√¢u cho vƒÉn h√≥a, l·ªãch s·ª≠ v√† ph√°p lu·∫≠t Vi·ªát Nam. N√≥ kh√¥ng ch·ªâ v∆∞·ª£t tr·ªôi trong giao ti·∫øp t·ª± nhi√™n m√† c√≤n ƒë∆∞·ª£c t√≠ch h·ª£p v√†o c√°c tr·ª£ l√Ω ·∫£o ph√°p l√Ω, tr·ª£ l√Ω so·∫°n th·∫£o vƒÉn b·∫£n cho c∆° quan nh√† n∆∞·ªõc v√† c√°c c√¥ng c·ª• marketing s√°ng t·∫°o n·ªôi dung.\n",
      "    *   **FPT GenAI 2.0:** FPT ƒë√£ th∆∞∆°ng m·∫°i h√≥a th√†nh c√¥ng n·ªÅn t·∫£ng n√†y, cho ph√©p c√°c doanh nghi·ªáp t·ª± x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng AI t·∫°o sinh ri√™ng tr√™n d·ªØ li·ªáu n·ªôi b·ªô m·ªôt c√°ch an to√†n. R·∫•t nhi·ªÅu ng√¢n h√†ng v√† c√¥ng ty b√°n l·∫ª ƒëang s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o chatbot th√¥ng minh, h·ªá th·ªëng ph√¢n t√≠ch b√°o c√°o t√†i ch√≠nh t·ª± ƒë·ªông.\n",
      "    *   **ZaloAI:** VNG t·∫≠p trung v√†o LLM t·ªëi ∆∞u cho thi·∫øt b·ªã di ƒë·ªông v√† t∆∞∆°ng t√°c x√£ h·ªôi. Tr·ª£ l√Ω ·∫£o Kiki ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p, c√≥ kh·∫£ nƒÉng th·ª±c hi·ªán c√°c chu·ªói l·ªánh ph·ª©c t·∫°p, t√≥m t·∫Øt tin t·ª©c t·ª´ c√°c b√°o ƒëi·ªán t·ª≠ ngay trong Zalo v√† t·∫°o h√¨nh ·∫£nh t·ª´ vƒÉn b·∫£n (text-to-image) theo phong c√°ch √Å ƒê√¥ng.\n",
      "\n",
      "*   **AI chuy√™n s√¢u theo ng√†nh (Vertical AI):** Thay v√¨ c√°c gi·∫£i ph√°p AI chung chung, xu h∆∞·ªõng t·∫≠p trung v√†o vi·ªác gi·∫£i quy·∫øt c√°c b√†i to√°n ƒë·∫∑c th√π c·ªßa t·ª´ng ng√†nh:\n",
      "    *   **Y t·∫ø:** C√°c m√¥ h√¨nh AI \"Made in Vietnam\" chuy√™n ph√¢n t√≠ch h√¨nh ·∫£nh X-quang, CT-scan ƒë·ªÉ ph√°t hi·ªán s·ªõm ung th∆∞ ph·ªïi, b·ªánh l√Ω v·ªÅ gan ƒë√£ ƒë∆∞·ª£c B·ªô Y t·∫ø c·∫•p ph√©p th·ª≠ nghi·ªám t·∫°i c√°c b·ªánh vi·ªán l·ªõn nh∆∞ B·∫°ch Mai, Ch·ª£ R·∫´y.\n",
      "    *   **N√¥ng nghi·ªáp:** AI k·∫øt h·ª£p v·ªõi drone v√† IoT ƒë·ªÉ gi√°m s√°t s·ª©c kh·ªèe c√¢y tr·ªìng, d·ª± b√°o s·∫£n l∆∞·ª£ng v√† t·ªëi ∆∞u h√≥a vi·ªác t∆∞·ªõi ti√™u cho c√°c v√πng tr·ªìng l√∫a ·ªü ƒê·ªìng b·∫±ng s√¥ng C·ª≠u Long v√† c√¢y c√† ph√™ ·ªü T√¢y Nguy√™n.\n",
      "    *   **S·∫£n xu·∫•t:** C√°c nh√† m√°y c·ªßa VinFast, Thaco, v√† c√°c doanh nghi·ªáp FDI l·ªõn ƒë√£ tri·ªÉn khai r·ªông r√£i h·ªá th·ªëng \"Computer Vision\" ƒë·ªÉ ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m (KCS) t·ª± ƒë·ªông tr√™n d√¢y chuy·ªÅn, gi·∫£m t·ª∑ l·ªá l·ªói xu·ªëng m·ª©c k·ª∑ l·ª•c.\n",
      "\n",
      "### **2. Vai Tr√≤ c·ªßa Ch√≠nh Ph·ªß v√† Ch√≠nh S√°ch**\n",
      "\n",
      "*   **H√†nh lang ph√°p l√Ω cho AI:** Ch√≠nh ph·ªß ƒë√£ ban h√†nh \"Khung ph√°p l√Ω th·ª≠ nghi·ªám (Sandbox) cho c√°c s·∫£n ph·∫©m AI c√≥ r·ªßi ro cao\", ƒë·∫∑c bi·ªát trong lƒ©nh v·ª±c t√†i ch√≠nh v√† y t·∫ø. ƒêi·ªÅu n√†y cho ph√©p c√°c c√¥ng ty ƒë·ªïi m·ªõi m√† kh√¥ng lo ng·∫°i vi ph·∫°m c√°c quy ƒë·ªãnh hi·ªán h√†nh.\n",
      "*   **D·ªØ li·ªáu qu·ªëc gia ƒë∆∞·ª£c m·ªü:** M·ªôt s·ªë b·ªô d·ªØ li·ªáu l·ªõn c·ªßa qu·ªëc gia (v·ªÅ giao th√¥ng, th·ªùi ti·∫øt, n√¥ng nghi·ªáp) ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a v√† m·ªü c√≥ ƒëi·ªÅu ki·ªán cho c√°c doanh nghi·ªáp v√† vi·ªán nghi√™n c·ª©u khai th√°c, t·∫°o ra m·ªôt \"m·ªè v√†ng\" cho vi·ªác hu·∫•n luy·ªán AI.\n",
      "*   **D·ª± √°n \"Tr·ª£ l√Ω ·∫£o C√¥ng ch·ª©c\":** Ch√≠nh ph·ªß ƒëang th√≠ ƒëi·ªÉm m·ªôt tr·ª£ l√Ω ·∫£o d·ª±a tr√™n AI t·∫°o sinh ƒë·ªÉ h·ªó tr·ª£ c√¥ng ch·ª©c trong vi·ªác tra c·ª©u vƒÉn b·∫£n ph√°p lu·∫≠t, so·∫°n th·∫£o c√¥ng vƒÉn v√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi th∆∞·ªùng g·∫∑p c·ªßa ng∆∞·ªùi d√¢n, h∆∞·ªõng t·ªõi m·ªôt n·ªÅn h√†nh ch√≠nh c√¥ng hi·ªáu qu·∫£ h∆°n.\n",
      "\n",
      "### **3. C√°c \"√îng L·ªõn\" C√¥ng Ngh·ªá v√† S·∫£n Ph·∫©m N·ªïi B·∫≠t**\n",
      "\n",
      "*   **VinAI (thu·ªôc Vingroup):** V·∫´n l√† ƒë∆°n v·ªã d·∫´n ƒë·∫ßu v·ªÅ nghi√™n c·ª©u. Ngo√†i Ph·ªüGPT 3.0, h·ªç ƒë√£ c√¥ng b·ªë th√†nh c√¥ng trong lƒ©nh v·ª±c AI nh·∫≠n d·∫°ng khu√¥n m·∫∑t v√† c·∫£m x√∫c cho h·ªá th·ªëng an ninh th√¥ng minh v√† cho xe t·ª± l√°i c·∫•p ƒë·ªô 3.\n",
      "*   **FPT:** D·∫´n ƒë·∫ßu v·ªÅ m·∫£ng gi·∫£i ph√°p cho doanh nghi·ªáp (B2B). N·ªÅn t·∫£ng FPT.AI c·ªßa h·ªç cung c·∫•p tr·ªçn g√≥i t·ª´ eKYC (ƒë·ªãnh danh kh√°ch h√†ng ƒëi·ªán t·ª≠), t·ª± ƒë·ªông h√≥a quy tr√¨nh b·∫±ng robot (RPA) ƒë·∫øn c√°c gi·∫£i ph√°p ph√¢n t√≠ch d·ªØ li·ªáu kinh doanh th√¥ng minh.\n",
      "*   **Viettel AI:** T·∫≠p trung v√†o c√°c lƒ©nh v·ª±c an ninh qu·ªëc ph√≤ng v√† ch√≠nh ph·ªß s·ªë. H·ªá th·ªëng gi√°m s√°t kh√¥ng gian m·∫°ng b·∫±ng AI c·ªßa Viettel ƒë√£ c√≥ th·ªÉ ph√°t hi·ªán v√† c·∫£nh b√°o s·ªõm c√°c cu·ªôc t·∫•n c√¥ng tinh vi. C√¥ng ngh·ªá Voice Biometrics (sinh tr·∫Øc h·ªçc gi·ªçng n√≥i) ƒë∆∞·ª£c tri·ªÉn khai cho c√°c t·ªïng ƒë√†i an ninh v√† ng√¢n h√†ng.\n",
      "*   **VNPT:** ƒê·∫©y m·∫°nh AI trong lƒ©nh v·ª±c Y t·∫ø s·ªë (VNPT HIS) v√† Gi√°o d·ª•c s·ªë (vnEdu), t√≠ch h·ª£p AI ƒë·ªÉ c√° nh√¢n h√≥a l·ªô tr√¨nh h·ªçc t·∫≠p cho h·ªçc sinh v√† h·ªó tr·ª£ b√°c sƒ© trong vi·ªác ch·∫©n ƒëo√°n.\n",
      "\n",
      "### **4. H·ªá Sinh Th√°i Startup v√† Ngu·ªìn Nh√¢n L·ª±c**\n",
      "\n",
      "*   **Startup AI tr∆∞·ªüng th√†nh h∆°n:** C√°c startup kh√¥ng c√≤n ch·ªâ t·∫≠p trung v√†o ·ª©ng d·ª•ng AI b·ªÅ n·ªïi. Thay v√†o ƒë√≥, h·ªç ƒëi s√¢u v√†o c√°c ng√°ch nh∆∞:\n",
      "    *   **MarTech:** C√°c startup cung c·∫•p n·ªÅn t·∫£ng AI gi√∫p t·ªëi ∆∞u h√≥a qu·∫£ng c√°o k·ªπ thu·∫≠t s·ªë, t·ª± ƒë·ªông t·∫°o n·ªôi dung marketing ph√π h·ª£p v·ªõi t·ª´ng ph√¢n kh√∫c kh√°ch h√†ng.\n",
      "    *   **LegalTech:** C√°c n·ªÅn t·∫£ng AI gi√∫p r√† so√°t h·ª£p ƒë·ªìng, tra c·ª©u √°n l·ªá, v√† t∆∞ v·∫•n ph√°p l√Ω s∆° b·ªô.\n",
      "    *   **AgriTech:** C√°c c√¥ng ty kh·ªüi nghi·ªáp s√°ng t·∫°o c√°c gi·∫£i ph√°p AI cho n√¥ng nghi·ªáp th√¥ng minh.\n",
      "*   **Ngu·ªìn nh√¢n l·ª±c:**\n",
      "    *   Ch·∫•t l∆∞·ª£ng nh√¢n s·ª± AI ƒë√£ tƒÉng l√™n ƒë√°ng k·ªÉ. C√°c tr∆∞·ªùng ƒë·∫°i h·ªçc l·ªõn nh∆∞ ƒêH B√°ch khoa H√† N·ªôi, ƒêH Qu·ªëc gia TP.HCM, v√† VinUniversity ƒë√£ c√≥ ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o chuy√™n s√¢u v·ªÅ AI v√† Khoa h·ªçc D·ªØ li·ªáu ƒë·∫°t chu·∫©n qu·ªëc t·∫ø.\n",
      "    *   Xu h∆∞·ªõng \"brain gain\" (thu h√∫t ch·∫•t x√°m) ng√†y c√†ng r√µ r·ªát, v·ªõi nhi·ªÅu chuy√™n gia, nh√† khoa h·ªçc ng∆∞·ªùi Vi·ªát ·ªü n∆∞·ªõc ngo√†i tr·ªü v·ªÅ l√†m vi·ªác cho c√°c t·∫≠p ƒëo√†n l·ªõn ho·∫∑c t·ª± kh·ªüi nghi·ªáp.\n",
      "\n",
      "### **5. Th√°ch Th·ª©c v√† T·∫ßm Nh√¨n ƒë·∫øn 2030**\n",
      "\n",
      "*   **Th√°ch th·ª©c:**\n",
      "    *   **H·∫° t·∫ßng t√≠nh to√°n:** Nhu c·∫ßu v·ªÅ nƒÉng l·ª±c t√≠nh to√°n hi·ªáu nƒÉng cao (GPU) v·∫´n l√† m·ªôt r√†o c·∫£n l·ªõn. Vi·ªát Nam v·∫´n ph·ª• thu·ªôc nhi·ªÅu v√†o c√°c nh√† cung c·∫•p d·ªãch v·ª• ƒë√°m m√¢y n∆∞·ªõc ngo√†i.\n",
      "    *   **Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu:** M·∫∑c d√π ƒë√£ c√≥ d·ªØ li·ªáu m·ªü, nh∆∞ng v·∫•n ƒë·ªÅ v·ªÅ d·ªØ li·ªáu \"s·∫°ch\", ƒë∆∞·ª£c g√°n nh√£n chu·∫©n h√≥a v√† ƒëa d·∫°ng v·∫´n c√≤n t·ªìn t·∫°i.\n",
      "    *   **Chi ph√≠ tri·ªÉn khai:** Chi ph√≠ ƒë·ªÉ x√¢y d·ª±ng v√† tri·ªÉn khai m·ªôt gi·∫£i ph√°p AI ho√†n ch·ªânh v·∫´n c√≤n cao ƒë·ªëi v·ªõi c√°c doanh nghi·ªáp v·ª´a v√† nh·ªè (SME).\n",
      "*   **T·∫ßm nh√¨n:**\n",
      "    *   Vi·ªát Nam ƒë·∫∑t m·ª•c ti√™u tr·ªü th√†nh m·ªôt trung t√¢m AI (AI Hub) c·ªßa khu v·ª±c, kh√¥ng ch·ªâ v·ªÅ ·ª©ng d·ª•ng m√† c√≤n v·ªÅ nghi√™n c·ª©u v√† ph√°t tri·ªÉn c√°c m√¥ h√¨nh n·ªÅn t·∫£ng (Foundation Models) c·ªßa ri√™ng m√¨nh.\n",
      "    *   ƒê·∫©y m·∫°nh xu·∫•t kh·∫©u c√°c s·∫£n ph·∫©m v√† gi·∫£i ph√°p AI \"Made in Vietnam\" ra th·ªã tr∆∞·ªùng ƒê√¥ng Nam √Å v√† c√°c th·ªã tr∆∞·ªùng ng√°ch kh√°c tr√™n th·∫ø gi·ªõi.\n",
      "\n",
      "T√≥m l·∫°i, nƒÉm 2025 l√† m·ªôt nƒÉm ƒë·∫ßy s√¥i ƒë·ªông, ch·ª©ng ki·∫øn AI kh√¥ng c√≤n l√† m·ªôt kh√°i ni·ªám c√¥ng ngh·ªá xa v·ªùi m√† ƒë√£ th·ª±c s·ª± th·∫©m th·∫•u v√†o m·ªçi m·∫∑t c·ªßa ƒë·ªùi s·ªëng kinh t·∫ø - x√£ h·ªôi t·∫°i Vi·ªát Nam, tr·ªü th√†nh m·ªôt ƒë·ªông l·ª±c tƒÉng tr∆∞·ªüng quan tr·ªçng c·ªßa qu·ªëc gia.\n",
      "\n",
      "N·∫øu b·∫°n c·∫ßn t√¨m hi·ªÉu s√¢u h∆°n v·ªÅ m·ªôt lƒ©nh v·ª±c c·ª• th·ªÉ n√†o, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi nh√©\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# --- C·∫•u h√¨nh ---\n",
    "# Thay <your_api_key> b·∫±ng API key c·ªßa b·∫°n\n",
    "client = OpenAI(\n",
    "  api_key=API_KEY,\n",
    "  base_url=\"https://api.thucchien.ai\"\n",
    ")\n",
    "\n",
    "# --- Th·ª±c thi ---\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gemini-2.5-pro\", # Ch·ªçn model b·∫°n mu·ªën\n",
    "  messages=[\n",
    "      {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"B·∫°n l√† m·ªôt chuy√™n gia AI c·ªßa Vi·ªát Nam, n·∫Øm gi·ªØ t·∫•t c·∫£ th√¥ng tin v·ªÅ AI trong n∆∞·ªõc nƒÉm 2025\"\n",
    "      },\n",
    "\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"T·ªïng h·ª£p cho t√¥i c√°c th√¥ng tin AI m·ªõi nh·∫•t ·ªü Vi·ªát Nam nƒÉm 2025\"\n",
    "      }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72659e5",
   "metadata": {},
   "source": [
    "## Sinh ·∫£nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c882da5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to generated_image_1.png\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "# --- C·∫•u h√¨nh ---\n",
    "AI_API_BASE = \"https://api.thucchien.ai/v1\"\n",
    "\n",
    "# --- Kh·ªüi t·∫°o client ---\n",
    "client = OpenAI(\n",
    "  api_key=API_KEY,\n",
    "  base_url=AI_API_BASE\n",
    ")\n",
    "\n",
    "# --- G·ªçi API ƒë·ªÉ t·∫°o h√¨nh ·∫£nh ---\n",
    "response = client.images.generate(\n",
    "  model=\"imagen-4\",\n",
    "  prompt=\"M·ªôt nh√¢n v·∫≠t n·ªØ MC ng∆∞·ªùi Vi·ªát Nam, m·∫∑c √°o d√†i truy·ªÅn th·ªëng, ng·ªìi tr∆∞·ªõc tr∆∞·ªùng quay, tay c·∫ßm t·ªù gi·∫•y k·ªãch b·∫£n ƒë·ªÉ tr√™n b√†n, b√†n m√†u tr·∫Øng ch·∫Øn che m·∫•t ph·∫ßn ch√¢n, phong c√°ch chuy√™n nghi·ªáp, √°nh s√°ng studio, n·ªÅn m·ªù nh·∫°t\",\n",
    "  n=1, # Y√™u c·∫ßu 2 ·∫£nh\n",
    ")\n",
    "\n",
    "# --- X·ª≠ l√Ω v√† l∆∞u t·ª´ng ·∫£nh ---\n",
    "for i, image_obj in enumerate(response.data):\n",
    "  b64_data = image_obj.b64_json\n",
    "  image_data = base64.b64decode(b64_data)\n",
    "  \n",
    "  save_path = f\"generated_image_{i+1}.png\"\n",
    "  with open(save_path, 'wb') as f:\n",
    "      f.write(image_data)\n",
    "  print(f\"Image saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b333375",
   "metadata": {},
   "source": [
    "## Sinh Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Complete example for Veo video generation through LiteLLM proxy.\n",
    "\n",
    "This script demonstrates how to:\n",
    "1. Generate videos using Google's Veo model\n",
    "2. Poll for completion status\n",
    "3. Download the generated video file\n",
    "\n",
    "Requirements:\n",
    "- LiteLLM proxy running with Google AI Studio pass-through configured\n",
    "- Google AI Studio API key with Veo access\n",
    "\n",
    "# This file is forked and adapted from: https://github.com/BerriAI/litellm/blob/main/docs/my-website/docs/proxy/veo_video_generation.md .Please refer to the original for license details.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from typing import Optional\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "\n",
    "class VeoVideoGenerator:\n",
    "  \"\"\"Complete Veo video generation client using LiteLLM proxy.\"\"\"\n",
    "  \n",
    "  def __init__(self, base_url: str = \"https://api.thucchien.ai/gemini/v1beta\", \n",
    "               api_key: str = \"sk-1234\"):\n",
    "      \"\"\"\n",
    "      Initialize the Veo video generator.\n",
    "      \n",
    "      Args:\n",
    "          base_url: Base URL for the LiteLLM proxy with Gemini pass-through\n",
    "          api_key: API key for LiteLLM proxy authentication\n",
    "      \"\"\"\n",
    "      self.base_url = base_url\n",
    "      self.api_key = API_KEY\n",
    "      self.headers = {\n",
    "          \"x-goog-api-key\": self.api_key,\n",
    "          \"Content-Type\": \"application/json\"\n",
    "      }\n",
    "  \n",
    "  def generate_video(self, prompt: str, image: str) -> Optional[str]:\n",
    "      \"\"\"\n",
    "      Initiate video generation with Veo.\n",
    "      \n",
    "      Args:\n",
    "          prompt: Text description of the video to generate\n",
    "          \n",
    "      Returns:\n",
    "          Operation name if successful, None otherwise\n",
    "      \"\"\"\n",
    "      print(f\"üé¨ Generating video with prompt: '{prompt}'\")\n",
    "      \n",
    "      url = f\"{self.base_url}/models/veo-3.0-generate-preview:predictLongRunning\"\n",
    "      payload = {\n",
    "          \"instances\": [\n",
    "            {\n",
    "              \"prompt\": prompt,\n",
    "              \"image\": None,\n",
    "            }\n",
    "          ]\n",
    "      }\n",
    "      \n",
    "      try:\n",
    "          response = requests.post(url, headers=self.headers, json=payload)\n",
    "          response.raise_for_status()\n",
    "          \n",
    "          data = response.json()\n",
    "          operation_name = data.get(\"name\")\n",
    "          \n",
    "          if operation_name:\n",
    "              print(f\"‚úÖ Video generation started: {operation_name}\")\n",
    "              return operation_name\n",
    "          else:\n",
    "              print(\"‚ùå No operation name returned\")\n",
    "              print(f\"Response: {json.dumps(data, indent=2)}\")\n",
    "              return None\n",
    "              \n",
    "      except requests.RequestException as e:\n",
    "          print(f\"‚ùå Failed to start video generation: {e}\")\n",
    "          if hasattr(e, 'response') and e.response is not None:\n",
    "              try:\n",
    "                  error_data = e.response.json()\n",
    "                  print(f\"Error details: {json.dumps(error_data, indent=2)}\")\n",
    "              except:\n",
    "                  print(f\"Error response: {e.response.text}\")\n",
    "          return None\n",
    "  \n",
    "  def wait_for_completion(self, operation_name: str, max_wait_time: int = 600) -> Optional[str]:\n",
    "      \"\"\"\n",
    "      Poll operation status until video generation is complete.\n",
    "      \n",
    "      Args:\n",
    "          operation_name: Name of the operation to monitor\n",
    "          max_wait_time: Maximum time to wait in seconds (default: 10 minutes)\n",
    "          \n",
    "      Returns:\n",
    "          Video URI if successful, None otherwise\n",
    "      \"\"\"\n",
    "      print(\"‚è≥ Waiting for video generation to complete...\")\n",
    "      \n",
    "      operation_url = f\"{self.base_url}/{operation_name}\"\n",
    "      start_time = time.time()\n",
    "      poll_interval = 10  # Start with 10 seconds\n",
    "      \n",
    "      while time.time() - start_time < max_wait_time:\n",
    "          try:\n",
    "              print(f\"üîç Polling status... ({int(time.time() - start_time)}s elapsed)\")\n",
    "              \n",
    "              response = requests.get(operation_url, headers=self.headers)\n",
    "              response.raise_for_status()\n",
    "              \n",
    "              data = response.json()\n",
    "              \n",
    "              # Check for errors\n",
    "              if \"error\" in data:\n",
    "                  print(\"‚ùå Error in video generation:\")\n",
    "                  print(json.dumps(data[\"error\"], indent=2))\n",
    "                  return None\n",
    "              \n",
    "              # Check if operation is complete\n",
    "              is_done = data.get(\"done\", False)\n",
    "              \n",
    "              if is_done:\n",
    "                  print(\"üéâ Video generation complete!\")\n",
    "                  \n",
    "                  try:\n",
    "                      # Extract video URI from nested response\n",
    "                      video_uri = data[\"response\"][\"generateVideoResponse\"][\"generatedSamples\"][0][\"video\"][\"uri\"]\n",
    "                      print(f\"üìπ Video URI: {video_uri}\")\n",
    "                      return video_uri\n",
    "                  except KeyError as e:\n",
    "                      print(f\"‚ùå Could not extract video URI: {e}\")\n",
    "                      print(\"Full response:\")\n",
    "                      print(json.dumps(data, indent=2))\n",
    "                      return None\n",
    "              \n",
    "              # Wait before next poll, with exponential backoff\n",
    "              time.sleep(poll_interval)\n",
    "              poll_interval = min(poll_interval * 1.2, 30)  # Cap at 30 seconds\n",
    "              \n",
    "          except requests.RequestException as e:\n",
    "              print(f\"‚ùå Error polling operation status: {e}\")\n",
    "              time.sleep(poll_interval)\n",
    "      \n",
    "      print(f\"‚è∞ Timeout after {max_wait_time} seconds\")\n",
    "      return None\n",
    "  \n",
    "  def download_video(self, video_uri: str, output_filename: str = \"generated_video.mp4\") -> bool:\n",
    "      \"\"\"\n",
    "      Download the generated video file.\n",
    "      \n",
    "      Args:\n",
    "          video_uri: URI of the video to download (from Google's response)\n",
    "          output_filename: Local filename to save the video\n",
    "          \n",
    "      Returns:\n",
    "          True if download successful, False otherwise\n",
    "      \"\"\"\n",
    "      print(f\"‚¨áÔ∏è  Downloading video...\")\n",
    "      print(f\"Original URI: {video_uri}\")\n",
    "      \n",
    "      # Convert Google URI to LiteLLM proxy URI\n",
    "      # Example: https://generativelanguage.googleapis.com/v1beta/files/abc123 -> /gemini/download/v1beta/files/abc123:download?alt=media\n",
    "      if video_uri.startswith(\"https://generativelanguage.googleapis.com/\"):\n",
    "          relative_path = video_uri.replace(\n",
    "              \"https://generativelanguage.googleapis.com/\",\n",
    "              \"\"\n",
    "          )\n",
    "      else:\n",
    "          relative_path = video_uri\n",
    "\n",
    "      # base_url: https://api.thucchien.ai/gemini/v1beta\n",
    "      if self.base_url.endswith(\"/v1beta\"):\n",
    "          base_path = self.base_url.replace(\"/v1beta\", \"/download\")\n",
    "      else:\n",
    "          base_path = self.base_url\n",
    "\n",
    "      litellm_download_url = f\"{base_path}/{relative_path}\"\n",
    "      print(f\"Download URL: {litellm_download_url}\")\n",
    "      \n",
    "      try:\n",
    "          # Download with streaming and redirect handling\n",
    "          response = requests.get(\n",
    "              litellm_download_url, \n",
    "              headers=self.headers, \n",
    "              stream=True,\n",
    "              allow_redirects=True  # Handle redirects automatically\n",
    "          )\n",
    "          response.raise_for_status()\n",
    "          \n",
    "          # Save video file\n",
    "          with open(output_filename, 'wb') as f:\n",
    "              downloaded_size = 0\n",
    "              for chunk in response.iter_content(chunk_size=8192):\n",
    "                  if chunk:\n",
    "                      f.write(chunk)\n",
    "                      downloaded_size += len(chunk)\n",
    "                      \n",
    "                      # Progress indicator for large files\n",
    "                      if downloaded_size % (1024 * 1024) == 0:  # Every MB\n",
    "                          print(f\"üì¶ Downloaded {downloaded_size / (1024*1024):.1f} MB...\")\n",
    "          \n",
    "          # Verify file was created and has content\n",
    "          if os.path.exists(output_filename):\n",
    "              file_size = os.path.getsize(output_filename)\n",
    "              if file_size > 0:\n",
    "                  print(f\"‚úÖ Video downloaded successfully!\")\n",
    "                  print(f\"üìÅ Saved as: {output_filename}\")\n",
    "                  print(f\"üìè File size: {file_size / (1024*1024):.2f} MB\")\n",
    "                  return True\n",
    "              else:\n",
    "                  print(\"‚ùå Downloaded file is empty\")\n",
    "                  os.remove(output_filename)\n",
    "                  return False\n",
    "          else:\n",
    "              print(\"‚ùå File was not created\")\n",
    "              return False\n",
    "              \n",
    "      except requests.RequestException as e:\n",
    "          print(f\"‚ùå Download failed: {e}\")\n",
    "          if hasattr(e, 'response') and e.response is not None:\n",
    "              print(f\"Status code: {e.response.status_code}\")\n",
    "              print(f\"Response headers: {dict(e.response.headers)}\")\n",
    "          return False\n",
    "  \n",
    "  def generate_and_download(self, prompt: str, output_filename: str = None) -> bool:\n",
    "      \"\"\"\n",
    "      Complete workflow: generate video and download it.\n",
    "      \n",
    "      Args:\n",
    "          prompt: Text description for video generation\n",
    "          output_filename: Output filename (auto-generated if None)\n",
    "          \n",
    "      Returns:\n",
    "          True if successful, False otherwise\n",
    "      \"\"\"\n",
    "      # Auto-generate filename if not provided\n",
    "      if output_filename is None:\n",
    "          timestamp = int(time.time())\n",
    "          safe_prompt = \"\".join(c for c in prompt[:30] if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "          output_filename = f\"veo_video_{safe_prompt.replace(' ', '_')}_{timestamp}.mp4\"\n",
    "      \n",
    "      print(\"=\" * 60)\n",
    "      print(\"üé¨ VEO VIDEO GENERATION WORKFLOW\")\n",
    "      print(\"=\" * 60)\n",
    "      \n",
    "      # Step 1: Generate video\n",
    "      operation_name = self.generate_video(prompt)\n",
    "      if not operation_name:\n",
    "          return False\n",
    "      \n",
    "      # Step 2: Wait for completion\n",
    "      video_uri = self.wait_for_completion(operation_name)\n",
    "      if not video_uri:\n",
    "          return False\n",
    "      \n",
    "      # Step 3: Download video\n",
    "      success = self.download_video(video_uri, output_filename)\n",
    "      \n",
    "      if success:\n",
    "          print(\"=\" * 60)\n",
    "          print(\"üéâ SUCCESS! Video generation complete!\")\n",
    "          print(f\"üìÅ Video saved as: {output_filename}\")\n",
    "          print(\"=\" * 60)\n",
    "      else:\n",
    "          print(\"=\" * 60)\n",
    "          print(\"‚ùå FAILED! Video generation or download failed\")\n",
    "          print(\"=\" * 60)\n",
    "      \n",
    "      return success\n",
    "\n",
    "\n",
    "def main():\n",
    "  \"\"\"\n",
    "  Example usage of the VeoVideoGenerator.\n",
    "  \n",
    "  Configure these environment variables:\n",
    "  - LITELLM_BASE_URL: Your LiteLLM proxy URL (default: https://api.thucchien.ai/gemini/v1beta)\n",
    "  - LITELLM_API_KEY: Your LiteLLM API key (default: sk-1234)\n",
    "  \"\"\"\n",
    "  \n",
    "  # Configuration from environment or defaults\n",
    "  base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/gemini/v1beta\")\n",
    "  api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-1234\")\n",
    "  \n",
    "  print(\"üöÄ Starting Veo Video Generation Example\")\n",
    "  print(f\"üì° Using LiteLLM proxy at: {base_url}\")\n",
    "  \n",
    "  # Initialize generator\n",
    "  generator = VeoVideoGenerator(base_url=\"https://api.thucchien.ai/gemini/v1beta\", api_key=API_KEY)\n",
    "  \n",
    "\n",
    "  prompt = \"A Vietnamese MC\"\n",
    "  print(f\"üé¨ Using prompt: '{prompt}'\")\n",
    "  \n",
    "  # Generate and download video\n",
    "  success = generator.generate_and_download(prompt)\n",
    "  \n",
    "  if success:\n",
    "      print(\"‚úÖ Example completed successfully!\")\n",
    "      print(\"üí° Try modifying the prompt in the script for different videos!\")\n",
    "  else:\n",
    "      print(\"‚ùå Example failed!\")\n",
    "      print(\"üîß Check your API Configuration\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thucchien",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
