{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ff9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"sk-0Tq-h91HomLFKER48zIiXA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c513472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chào bạn. Với tư cách là một chuyên gia AI tại Việt Nam, tôi rất vui được cung cấp cho bạn một bức tranh toàn cảnh và chi tiết về lĩnh vực trí tuệ nhân tạo (AI) trong nước, cập nhật đến thời điểm hiện tại, năm 2025.\n",
      "\n",
      "Năm 2025 là một năm bản lề, đánh dấu sự trưởng thành vượt bậc của hệ sinh thái AI Việt Nam. Chúng ta đã chuyển từ giai đoạn \"thử nghiệm và học hỏi\" sang giai đoạn \"triển khai sâu rộng và tạo ra giá trị thực tiễn\".\n",
      "\n",
      "Dưới đây là những thông tin tổng hợp nổi bật nhất:\n",
      "\n",
      "### **1. Xu Hướng Chủ Đạo: AI Tạo Sinh và AI Theo Ngành Dọc**\n",
      "\n",
      "*   **Bùng nổ các Mô hình Ngôn ngữ Lớn (LLM) thuần Việt:**\n",
      "    *   **PhởGPT 3.0 (của VinAI):** Đã trở thành mô hình ngôn ngữ tiếng Việt mạnh mẽ nhất, được tinh chỉnh sâu cho văn hóa, lịch sử và pháp luật Việt Nam. Nó không chỉ vượt trội trong giao tiếp tự nhiên mà còn được tích hợp vào các trợ lý ảo pháp lý, trợ lý soạn thảo văn bản cho cơ quan nhà nước và các công cụ marketing sáng tạo nội dung.\n",
      "    *   **FPT GenAI 2.0:** FPT đã thương mại hóa thành công nền tảng này, cho phép các doanh nghiệp tự xây dựng các ứng dụng AI tạo sinh riêng trên dữ liệu nội bộ một cách an toàn. Rất nhiều ngân hàng và công ty bán lẻ đang sử dụng để tạo chatbot thông minh, hệ thống phân tích báo cáo tài chính tự động.\n",
      "    *   **ZaloAI:** VNG tập trung vào LLM tối ưu cho thiết bị di động và tương tác xã hội. Trợ lý ảo Kiki đã được nâng cấp, có khả năng thực hiện các chuỗi lệnh phức tạp, tóm tắt tin tức từ các báo điện tử ngay trong Zalo và tạo hình ảnh từ văn bản (text-to-image) theo phong cách Á Đông.\n",
      "\n",
      "*   **AI chuyên sâu theo ngành (Vertical AI):** Thay vì các giải pháp AI chung chung, xu hướng tập trung vào việc giải quyết các bài toán đặc thù của từng ngành:\n",
      "    *   **Y tế:** Các mô hình AI \"Made in Vietnam\" chuyên phân tích hình ảnh X-quang, CT-scan để phát hiện sớm ung thư phổi, bệnh lý về gan đã được Bộ Y tế cấp phép thử nghiệm tại các bệnh viện lớn như Bạch Mai, Chợ Rẫy.\n",
      "    *   **Nông nghiệp:** AI kết hợp với drone và IoT để giám sát sức khỏe cây trồng, dự báo sản lượng và tối ưu hóa việc tưới tiêu cho các vùng trồng lúa ở Đồng bằng sông Cửu Long và cây cà phê ở Tây Nguyên.\n",
      "    *   **Sản xuất:** Các nhà máy của VinFast, Thaco, và các doanh nghiệp FDI lớn đã triển khai rộng rãi hệ thống \"Computer Vision\" để kiểm soát chất lượng sản phẩm (KCS) tự động trên dây chuyền, giảm tỷ lệ lỗi xuống mức kỷ lục.\n",
      "\n",
      "### **2. Vai Trò của Chính Phủ và Chính Sách**\n",
      "\n",
      "*   **Hành lang pháp lý cho AI:** Chính phủ đã ban hành \"Khung pháp lý thử nghiệm (Sandbox) cho các sản phẩm AI có rủi ro cao\", đặc biệt trong lĩnh vực tài chính và y tế. Điều này cho phép các công ty đổi mới mà không lo ngại vi phạm các quy định hiện hành.\n",
      "*   **Dữ liệu quốc gia được mở:** Một số bộ dữ liệu lớn của quốc gia (về giao thông, thời tiết, nông nghiệp) đã được chuẩn hóa và mở có điều kiện cho các doanh nghiệp và viện nghiên cứu khai thác, tạo ra một \"mỏ vàng\" cho việc huấn luyện AI.\n",
      "*   **Dự án \"Trợ lý ảo Công chức\":** Chính phủ đang thí điểm một trợ lý ảo dựa trên AI tạo sinh để hỗ trợ công chức trong việc tra cứu văn bản pháp luật, soạn thảo công văn và trả lời các câu hỏi thường gặp của người dân, hướng tới một nền hành chính công hiệu quả hơn.\n",
      "\n",
      "### **3. Các \"Ông Lớn\" Công Nghệ và Sản Phẩm Nổi Bật**\n",
      "\n",
      "*   **VinAI (thuộc Vingroup):** Vẫn là đơn vị dẫn đầu về nghiên cứu. Ngoài PhởGPT 3.0, họ đã công bố thành công trong lĩnh vực AI nhận dạng khuôn mặt và cảm xúc cho hệ thống an ninh thông minh và cho xe tự lái cấp độ 3.\n",
      "*   **FPT:** Dẫn đầu về mảng giải pháp cho doanh nghiệp (B2B). Nền tảng FPT.AI của họ cung cấp trọn gói từ eKYC (định danh khách hàng điện tử), tự động hóa quy trình bằng robot (RPA) đến các giải pháp phân tích dữ liệu kinh doanh thông minh.\n",
      "*   **Viettel AI:** Tập trung vào các lĩnh vực an ninh quốc phòng và chính phủ số. Hệ thống giám sát không gian mạng bằng AI của Viettel đã có thể phát hiện và cảnh báo sớm các cuộc tấn công tinh vi. Công nghệ Voice Biometrics (sinh trắc học giọng nói) được triển khai cho các tổng đài an ninh và ngân hàng.\n",
      "*   **VNPT:** Đẩy mạnh AI trong lĩnh vực Y tế số (VNPT HIS) và Giáo dục số (vnEdu), tích hợp AI để cá nhân hóa lộ trình học tập cho học sinh và hỗ trợ bác sĩ trong việc chẩn đoán.\n",
      "\n",
      "### **4. Hệ Sinh Thái Startup và Nguồn Nhân Lực**\n",
      "\n",
      "*   **Startup AI trưởng thành hơn:** Các startup không còn chỉ tập trung vào ứng dụng AI bề nổi. Thay vào đó, họ đi sâu vào các ngách như:\n",
      "    *   **MarTech:** Các startup cung cấp nền tảng AI giúp tối ưu hóa quảng cáo kỹ thuật số, tự động tạo nội dung marketing phù hợp với từng phân khúc khách hàng.\n",
      "    *   **LegalTech:** Các nền tảng AI giúp rà soát hợp đồng, tra cứu án lệ, và tư vấn pháp lý sơ bộ.\n",
      "    *   **AgriTech:** Các công ty khởi nghiệp sáng tạo các giải pháp AI cho nông nghiệp thông minh.\n",
      "*   **Nguồn nhân lực:**\n",
      "    *   Chất lượng nhân sự AI đã tăng lên đáng kể. Các trường đại học lớn như ĐH Bách khoa Hà Nội, ĐH Quốc gia TP.HCM, và VinUniversity đã có chương trình đào tạo chuyên sâu về AI và Khoa học Dữ liệu đạt chuẩn quốc tế.\n",
      "    *   Xu hướng \"brain gain\" (thu hút chất xám) ngày càng rõ rệt, với nhiều chuyên gia, nhà khoa học người Việt ở nước ngoài trở về làm việc cho các tập đoàn lớn hoặc tự khởi nghiệp.\n",
      "\n",
      "### **5. Thách Thức và Tầm Nhìn đến 2030**\n",
      "\n",
      "*   **Thách thức:**\n",
      "    *   **Hạ tầng tính toán:** Nhu cầu về năng lực tính toán hiệu năng cao (GPU) vẫn là một rào cản lớn. Việt Nam vẫn phụ thuộc nhiều vào các nhà cung cấp dịch vụ đám mây nước ngoài.\n",
      "    *   **Chất lượng dữ liệu:** Mặc dù đã có dữ liệu mở, nhưng vấn đề về dữ liệu \"sạch\", được gán nhãn chuẩn hóa và đa dạng vẫn còn tồn tại.\n",
      "    *   **Chi phí triển khai:** Chi phí để xây dựng và triển khai một giải pháp AI hoàn chỉnh vẫn còn cao đối với các doanh nghiệp vừa và nhỏ (SME).\n",
      "*   **Tầm nhìn:**\n",
      "    *   Việt Nam đặt mục tiêu trở thành một trung tâm AI (AI Hub) của khu vực, không chỉ về ứng dụng mà còn về nghiên cứu và phát triển các mô hình nền tảng (Foundation Models) của riêng mình.\n",
      "    *   Đẩy mạnh xuất khẩu các sản phẩm và giải pháp AI \"Made in Vietnam\" ra thị trường Đông Nam Á và các thị trường ngách khác trên thế giới.\n",
      "\n",
      "Tóm lại, năm 2025 là một năm đầy sôi động, chứng kiến AI không còn là một khái niệm công nghệ xa vời mà đã thực sự thẩm thấu vào mọi mặt của đời sống kinh tế - xã hội tại Việt Nam, trở thành một động lực tăng trưởng quan trọng của quốc gia.\n",
      "\n",
      "Nếu bạn cần tìm hiểu sâu hơn về một lĩnh vực cụ thể nào, đừng ngần ngại hỏi nhé\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# --- Cấu hình ---\n",
    "# Thay <your_api_key> bằng API key của bạn\n",
    "client = OpenAI(\n",
    "  api_key=API_KEY,\n",
    "  base_url=\"https://api.thucchien.ai\"\n",
    ")\n",
    "\n",
    "# --- Thực thi ---\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gemini-2.5-pro\", # Chọn model bạn muốn\n",
    "  messages=[\n",
    "      {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Bạn là một chuyên gia AI của Việt Nam, nắm giữ tất cả thông tin về AI trong nước năm 2025\"\n",
    "      },\n",
    "\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"Tổng hợp cho tôi các thông tin AI mới nhất ở Việt Nam năm 2025\"\n",
    "      }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72659e5",
   "metadata": {},
   "source": [
    "## Sinh ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c882da5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to generated_image_1.png\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "# --- Cấu hình ---\n",
    "AI_API_BASE = \"https://api.thucchien.ai/v1\"\n",
    "\n",
    "# --- Khởi tạo client ---\n",
    "client = OpenAI(\n",
    "  api_key=API_KEY,\n",
    "  base_url=AI_API_BASE\n",
    ")\n",
    "\n",
    "# --- Gọi API để tạo hình ảnh ---\n",
    "response = client.images.generate(\n",
    "  model=\"imagen-4\",\n",
    "  prompt=\"Một nhân vật nữ MC người Việt Nam, mặc áo dài truyền thống, ngồi trước trường quay, tay cầm tờ giấy kịch bản để trên bàn, bàn màu trắng chắn che mất phần chân, phong cách chuyên nghiệp, ánh sáng studio, nền mờ nhạt\",\n",
    "  n=1, # Yêu cầu 2 ảnh\n",
    ")\n",
    "\n",
    "# --- Xử lý và lưu từng ảnh ---\n",
    "for i, image_obj in enumerate(response.data):\n",
    "  b64_data = image_obj.b64_json\n",
    "  image_data = base64.b64decode(b64_data)\n",
    "  \n",
    "  save_path = f\"generated_image_{i+1}.png\"\n",
    "  with open(save_path, 'wb') as f:\n",
    "      f.write(image_data)\n",
    "  print(f\"Image saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b333375",
   "metadata": {},
   "source": [
    "## Sinh Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Complete example for Veo video generation through LiteLLM proxy.\n",
    "\n",
    "This script demonstrates how to:\n",
    "1. Generate videos using Google's Veo model\n",
    "2. Poll for completion status\n",
    "3. Download the generated video file\n",
    "\n",
    "Requirements:\n",
    "- LiteLLM proxy running with Google AI Studio pass-through configured\n",
    "- Google AI Studio API key with Veo access\n",
    "\n",
    "# This file is forked and adapted from: https://github.com/BerriAI/litellm/blob/main/docs/my-website/docs/proxy/veo_video_generation.md .Please refer to the original for license details.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from typing import Optional\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "\n",
    "class VeoVideoGenerator:\n",
    "  \"\"\"Complete Veo video generation client using LiteLLM proxy.\"\"\"\n",
    "  \n",
    "  def __init__(self, base_url: str = \"https://api.thucchien.ai/gemini/v1beta\", \n",
    "               api_key: str = \"sk-1234\"):\n",
    "      \"\"\"\n",
    "      Initialize the Veo video generator.\n",
    "      \n",
    "      Args:\n",
    "          base_url: Base URL for the LiteLLM proxy with Gemini pass-through\n",
    "          api_key: API key for LiteLLM proxy authentication\n",
    "      \"\"\"\n",
    "      self.base_url = base_url\n",
    "      self.api_key = API_KEY\n",
    "      self.headers = {\n",
    "          \"x-goog-api-key\": self.api_key,\n",
    "          \"Content-Type\": \"application/json\"\n",
    "      }\n",
    "  \n",
    "  def generate_video(self, prompt: str, image: str) -> Optional[str]:\n",
    "      \"\"\"\n",
    "      Initiate video generation with Veo.\n",
    "      \n",
    "      Args:\n",
    "          prompt: Text description of the video to generate\n",
    "          \n",
    "      Returns:\n",
    "          Operation name if successful, None otherwise\n",
    "      \"\"\"\n",
    "      print(f\"🎬 Generating video with prompt: '{prompt}'\")\n",
    "      \n",
    "      url = f\"{self.base_url}/models/veo-3.0-generate-preview:predictLongRunning\"\n",
    "      payload = {\n",
    "          \"instances\": [\n",
    "            {\n",
    "              \"prompt\": prompt,\n",
    "              \"image\": None,\n",
    "            }\n",
    "          ]\n",
    "      }\n",
    "      \n",
    "      try:\n",
    "          response = requests.post(url, headers=self.headers, json=payload)\n",
    "          response.raise_for_status()\n",
    "          \n",
    "          data = response.json()\n",
    "          operation_name = data.get(\"name\")\n",
    "          \n",
    "          if operation_name:\n",
    "              print(f\"✅ Video generation started: {operation_name}\")\n",
    "              return operation_name\n",
    "          else:\n",
    "              print(\"❌ No operation name returned\")\n",
    "              print(f\"Response: {json.dumps(data, indent=2)}\")\n",
    "              return None\n",
    "              \n",
    "      except requests.RequestException as e:\n",
    "          print(f\"❌ Failed to start video generation: {e}\")\n",
    "          if hasattr(e, 'response') and e.response is not None:\n",
    "              try:\n",
    "                  error_data = e.response.json()\n",
    "                  print(f\"Error details: {json.dumps(error_data, indent=2)}\")\n",
    "              except:\n",
    "                  print(f\"Error response: {e.response.text}\")\n",
    "          return None\n",
    "  \n",
    "  def wait_for_completion(self, operation_name: str, max_wait_time: int = 600) -> Optional[str]:\n",
    "      \"\"\"\n",
    "      Poll operation status until video generation is complete.\n",
    "      \n",
    "      Args:\n",
    "          operation_name: Name of the operation to monitor\n",
    "          max_wait_time: Maximum time to wait in seconds (default: 10 minutes)\n",
    "          \n",
    "      Returns:\n",
    "          Video URI if successful, None otherwise\n",
    "      \"\"\"\n",
    "      print(\"⏳ Waiting for video generation to complete...\")\n",
    "      \n",
    "      operation_url = f\"{self.base_url}/{operation_name}\"\n",
    "      start_time = time.time()\n",
    "      poll_interval = 10  # Start with 10 seconds\n",
    "      \n",
    "      while time.time() - start_time < max_wait_time:\n",
    "          try:\n",
    "              print(f\"🔍 Polling status... ({int(time.time() - start_time)}s elapsed)\")\n",
    "              \n",
    "              response = requests.get(operation_url, headers=self.headers)\n",
    "              response.raise_for_status()\n",
    "              \n",
    "              data = response.json()\n",
    "              \n",
    "              # Check for errors\n",
    "              if \"error\" in data:\n",
    "                  print(\"❌ Error in video generation:\")\n",
    "                  print(json.dumps(data[\"error\"], indent=2))\n",
    "                  return None\n",
    "              \n",
    "              # Check if operation is complete\n",
    "              is_done = data.get(\"done\", False)\n",
    "              \n",
    "              if is_done:\n",
    "                  print(\"🎉 Video generation complete!\")\n",
    "                  \n",
    "                  try:\n",
    "                      # Extract video URI from nested response\n",
    "                      video_uri = data[\"response\"][\"generateVideoResponse\"][\"generatedSamples\"][0][\"video\"][\"uri\"]\n",
    "                      print(f\"📹 Video URI: {video_uri}\")\n",
    "                      return video_uri\n",
    "                  except KeyError as e:\n",
    "                      print(f\"❌ Could not extract video URI: {e}\")\n",
    "                      print(\"Full response:\")\n",
    "                      print(json.dumps(data, indent=2))\n",
    "                      return None\n",
    "              \n",
    "              # Wait before next poll, with exponential backoff\n",
    "              time.sleep(poll_interval)\n",
    "              poll_interval = min(poll_interval * 1.2, 30)  # Cap at 30 seconds\n",
    "              \n",
    "          except requests.RequestException as e:\n",
    "              print(f\"❌ Error polling operation status: {e}\")\n",
    "              time.sleep(poll_interval)\n",
    "      \n",
    "      print(f\"⏰ Timeout after {max_wait_time} seconds\")\n",
    "      return None\n",
    "  \n",
    "  def download_video(self, video_uri: str, output_filename: str = \"generated_video.mp4\") -> bool:\n",
    "      \"\"\"\n",
    "      Download the generated video file.\n",
    "      \n",
    "      Args:\n",
    "          video_uri: URI of the video to download (from Google's response)\n",
    "          output_filename: Local filename to save the video\n",
    "          \n",
    "      Returns:\n",
    "          True if download successful, False otherwise\n",
    "      \"\"\"\n",
    "      print(f\"⬇️  Downloading video...\")\n",
    "      print(f\"Original URI: {video_uri}\")\n",
    "      \n",
    "      # Convert Google URI to LiteLLM proxy URI\n",
    "      # Example: https://generativelanguage.googleapis.com/v1beta/files/abc123 -> /gemini/download/v1beta/files/abc123:download?alt=media\n",
    "      if video_uri.startswith(\"https://generativelanguage.googleapis.com/\"):\n",
    "          relative_path = video_uri.replace(\n",
    "              \"https://generativelanguage.googleapis.com/\",\n",
    "              \"\"\n",
    "          )\n",
    "      else:\n",
    "          relative_path = video_uri\n",
    "\n",
    "      # base_url: https://api.thucchien.ai/gemini/v1beta\n",
    "      if self.base_url.endswith(\"/v1beta\"):\n",
    "          base_path = self.base_url.replace(\"/v1beta\", \"/download\")\n",
    "      else:\n",
    "          base_path = self.base_url\n",
    "\n",
    "      litellm_download_url = f\"{base_path}/{relative_path}\"\n",
    "      print(f\"Download URL: {litellm_download_url}\")\n",
    "      \n",
    "      try:\n",
    "          # Download with streaming and redirect handling\n",
    "          response = requests.get(\n",
    "              litellm_download_url, \n",
    "              headers=self.headers, \n",
    "              stream=True,\n",
    "              allow_redirects=True  # Handle redirects automatically\n",
    "          )\n",
    "          response.raise_for_status()\n",
    "          \n",
    "          # Save video file\n",
    "          with open(output_filename, 'wb') as f:\n",
    "              downloaded_size = 0\n",
    "              for chunk in response.iter_content(chunk_size=8192):\n",
    "                  if chunk:\n",
    "                      f.write(chunk)\n",
    "                      downloaded_size += len(chunk)\n",
    "                      \n",
    "                      # Progress indicator for large files\n",
    "                      if downloaded_size % (1024 * 1024) == 0:  # Every MB\n",
    "                          print(f\"📦 Downloaded {downloaded_size / (1024*1024):.1f} MB...\")\n",
    "          \n",
    "          # Verify file was created and has content\n",
    "          if os.path.exists(output_filename):\n",
    "              file_size = os.path.getsize(output_filename)\n",
    "              if file_size > 0:\n",
    "                  print(f\"✅ Video downloaded successfully!\")\n",
    "                  print(f\"📁 Saved as: {output_filename}\")\n",
    "                  print(f\"📏 File size: {file_size / (1024*1024):.2f} MB\")\n",
    "                  return True\n",
    "              else:\n",
    "                  print(\"❌ Downloaded file is empty\")\n",
    "                  os.remove(output_filename)\n",
    "                  return False\n",
    "          else:\n",
    "              print(\"❌ File was not created\")\n",
    "              return False\n",
    "              \n",
    "      except requests.RequestException as e:\n",
    "          print(f\"❌ Download failed: {e}\")\n",
    "          if hasattr(e, 'response') and e.response is not None:\n",
    "              print(f\"Status code: {e.response.status_code}\")\n",
    "              print(f\"Response headers: {dict(e.response.headers)}\")\n",
    "          return False\n",
    "  \n",
    "  def generate_and_download(self, prompt: str, output_filename: str = None) -> bool:\n",
    "      \"\"\"\n",
    "      Complete workflow: generate video and download it.\n",
    "      \n",
    "      Args:\n",
    "          prompt: Text description for video generation\n",
    "          output_filename: Output filename (auto-generated if None)\n",
    "          \n",
    "      Returns:\n",
    "          True if successful, False otherwise\n",
    "      \"\"\"\n",
    "      # Auto-generate filename if not provided\n",
    "      if output_filename is None:\n",
    "          timestamp = int(time.time())\n",
    "          safe_prompt = \"\".join(c for c in prompt[:30] if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "          output_filename = f\"veo_video_{safe_prompt.replace(' ', '_')}_{timestamp}.mp4\"\n",
    "      \n",
    "      print(\"=\" * 60)\n",
    "      print(\"🎬 VEO VIDEO GENERATION WORKFLOW\")\n",
    "      print(\"=\" * 60)\n",
    "      \n",
    "      # Step 1: Generate video\n",
    "      operation_name = self.generate_video(prompt)\n",
    "      if not operation_name:\n",
    "          return False\n",
    "      \n",
    "      # Step 2: Wait for completion\n",
    "      video_uri = self.wait_for_completion(operation_name)\n",
    "      if not video_uri:\n",
    "          return False\n",
    "      \n",
    "      # Step 3: Download video\n",
    "      success = self.download_video(video_uri, output_filename)\n",
    "      \n",
    "      if success:\n",
    "          print(\"=\" * 60)\n",
    "          print(\"🎉 SUCCESS! Video generation complete!\")\n",
    "          print(f\"📁 Video saved as: {output_filename}\")\n",
    "          print(\"=\" * 60)\n",
    "      else:\n",
    "          print(\"=\" * 60)\n",
    "          print(\"❌ FAILED! Video generation or download failed\")\n",
    "          print(\"=\" * 60)\n",
    "      \n",
    "      return success\n",
    "\n",
    "\n",
    "def main():\n",
    "  \"\"\"\n",
    "  Example usage of the VeoVideoGenerator.\n",
    "  \n",
    "  Configure these environment variables:\n",
    "  - LITELLM_BASE_URL: Your LiteLLM proxy URL (default: https://api.thucchien.ai/gemini/v1beta)\n",
    "  - LITELLM_API_KEY: Your LiteLLM API key (default: sk-1234)\n",
    "  \"\"\"\n",
    "  \n",
    "  # Configuration from environment or defaults\n",
    "  base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/gemini/v1beta\")\n",
    "  api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-1234\")\n",
    "  \n",
    "  print(\"🚀 Starting Veo Video Generation Example\")\n",
    "  print(f\"📡 Using LiteLLM proxy at: {base_url}\")\n",
    "  \n",
    "  # Initialize generator\n",
    "  generator = VeoVideoGenerator(base_url=\"https://api.thucchien.ai/gemini/v1beta\", api_key=API_KEY)\n",
    "  \n",
    "\n",
    "  prompt = \"A Vietnamese MC\"\n",
    "  print(f\"🎬 Using prompt: '{prompt}'\")\n",
    "  \n",
    "  # Generate and download video\n",
    "  success = generator.generate_and_download(prompt)\n",
    "  \n",
    "  if success:\n",
    "      print(\"✅ Example completed successfully!\")\n",
    "      print(\"💡 Try modifying the prompt in the script for different videos!\")\n",
    "  else:\n",
    "      print(\"❌ Example failed!\")\n",
    "      print(\"🔧 Check your API Configuration\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thucchien",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
